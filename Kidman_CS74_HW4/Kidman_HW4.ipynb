{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Classification with Machine Learning Models\n",
        "\n",
        "**Instructions:** For part 1, your goal is to build binary classification models and report the scores of the models.\n",
        "As deliverables of this part, you will submit your best model prediction on the provided test set.\n",
        "Your best model performance on the test set would outperform the baseline score provided by\n",
        "the instructor. <font color='blue'>The baseline score for part 1 is 80.00.\n",
        "\n"
      ],
      "metadata": {
        "id": "W-Tj7-QTm7sC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Prepare the data"
      ],
      "metadata": {
        "id": "jxqZDqiDl410"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First start by importing the necessary libraries and reading the data:"
      ],
      "metadata": {
        "id": "m93zVqgJnBf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autograd.numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AXrhUtsvul0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa40d76d-069c-4a77-ec1f-0617b26904b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the data:\n",
        "amazon_train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/hw4-train-new.csv')\n",
        "#amazon_train_data.head()\n",
        "\n",
        "# Create a more readable table with only the necessary information displayed:\n",
        "df = pd.DataFrame([amazon_train_data['overall'], amazon_train_data['reviewText'], amazon_train_data['summary'], amazon_train_data['label']]).T\n",
        "df.head()"
      ],
      "metadata": {
        "id": "cKONNht0vqdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "bec071a6-1690-4c6d-cab1-8511376c9272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  overall                                         reviewText  \\\n",
              "0       4  great value,very sturdy case for the money. cl...   \n",
              "1       4  this works great, now that we know the trick.\\...   \n",
              "2       2  very thin and fragile, easily damaged.  i foun...   \n",
              "3       3  i like them but the fit and finish is not that...   \n",
              "4       4  sound is incredible for as small as it is. the...   \n",
              "\n",
              "                                             summary label  \n",
              "0                                         good value     1  \n",
              "1  Works great - but you must use on a wooden sur...     1  \n",
              "2  easily damaged. I found it not for cold weathe...     0  \n",
              "3                        Not the best but they work.     0  \n",
              "4                                     Worth the buy!     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bacca2e-503a-4d2c-95fe-c774fc38b2b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>great value,very sturdy case for the money. cl...</td>\n",
              "      <td>good value</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>this works great, now that we know the trick.\\...</td>\n",
              "      <td>Works great - but you must use on a wooden sur...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>very thin and fragile, easily damaged.  i foun...</td>\n",
              "      <td>easily damaged. I found it not for cold weathe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>i like them but the fit and finish is not that...</td>\n",
              "      <td>Not the best but they work.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sound is incredible for as small as it is. the...</td>\n",
              "      <td>Worth the buy!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bacca2e-503a-4d2c-95fe-c774fc38b2b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bacca2e-503a-4d2c-95fe-c774fc38b2b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bacca2e-503a-4d2c-95fe-c774fc38b2b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1801826c-d9be-4cb2-98ef-d9d20b5d630e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1801826c-d9be-4cb2-98ef-d9d20b5d630e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1801826c-d9be-4cb2-98ef-d9d20b5d630e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"overall\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19791,\n        \"samples\": [\n          \"is exactly what i expected for the price, not bad at all for my needs.\",\n          \"didn't realize this nerf gun took batteries - ugh!  it's so heavy too my 6 year old barely plays with it anymore and heads for the smaller, lighter ones.\",\n          \"perfect replacement for oem part at 1/3rd the cost.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15129,\n        \"samples\": [\n          \"Not Good At All -- BORING\",\n          \"but it's granulated like cane sugar so just buy the regular Monk Fruit ...\",\n          \"Functional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to do basic text processing by eliminating unnecessary spaces and capitalization:\n",
        "def process_text(text):\n",
        "  cleaned_text = \"\"  # First replace any characters that are not letters or spaces\n",
        "  for char in text:\n",
        "    if char.isalpha() or char.isspace():\n",
        "      cleaned_text += char\n",
        "    else:\n",
        "      cleaned_text += \" \"\n",
        "\n",
        "  cleaned_text = cleaned_text.lower().strip()  # Turns all text into lower case\n",
        "\n",
        "  return cleaned_text\n",
        "\n",
        "\n",
        "# Combine reviewText and summary data (dropping any empty review rows):\n",
        "amazon_train_data['combinedData'] = amazon_train_data['reviewText'].fillna(\"\") + \" \" + amazon_train_data['summary'].fillna(\"\")\n",
        "\n",
        "# Apply text processing to combined train data:\n",
        "amazon_train_data['combinedData'] = amazon_train_data['combinedData'].apply(process_text)"
      ],
      "metadata": {
        "id": "7he7-JNjGJE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Model 1, Logistic Regression"
      ],
      "metadata": {
        "id": "sGi7I4qAmAzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following the example notebook at the end of Lecture 12, now utilize a vectorizer to assign numerical values to reviewText:\n",
        "# Initalize vectorizer for LogisticRegression:\n",
        "lr_vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=1000)\n",
        "\n",
        "# Fit vectorizer and transform text into features\n",
        "lr_train_features = lr_vectorizer.fit_transform(amazon_train_data['combinedData'].tolist())\n",
        "\n",
        "# Now split into training and validation sets:\n",
        "lr_train_x,lr_val_x,lr_train_y,lr_val_y = train_test_split(lr_train_features, amazon_train_data['label'], test_size=0.2, random_state=37462)\n"
      ],
      "metadata": {
        "id": "S9wlxFaZcDxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model using Logistic Regression\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Define parameter grid, basing off of LogisticRegressionCV API documentation\n",
        "param_grid_log_reg = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Each of the values in Cs describes the inverse of regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # i.e. regularization\n",
        "    'solver': ['liblinear', 'saga']  # Algorithm to use in the optimization problem\n",
        "}\n",
        "\n",
        "# Grid search parameters using 5-fold cross-validation and apply to training set\n",
        "grid_log_reg = GridSearchCV(log_reg, param_grid_log_reg, cv=5, verbose=5, scoring='f1_macro', error_score=0.0)  # cv = int or cross-validation generator\n",
        "grid_log_reg.fit(lr_train_x, lr_train_y)\n",
        "\n",
        "best_lr_model = grid_log_reg.best_estimator_\n",
        "print(\"\\033[91m\", \"\\n\\nBest hyperparamaters for Logistic Regression: \", grid_log_reg.best_params_, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSTtqi-GjZzC",
        "outputId": "038e5117-8613-442f-f32d-d20016a82ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV 1/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.534 total time=   0.1s\n",
            "[CV 2/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.553 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.534 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.539 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, penalty=l1, solver=liblinear;, score=0.528 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.533 total time=   0.3s\n",
            "[CV 2/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.556 total time=   0.3s\n",
            "[CV 3/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.535 total time=   0.3s\n",
            "[CV 4/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.536 total time=   0.3s\n",
            "[CV 5/5] END ...C=0.01, penalty=l1, solver=saga;, score=0.529 total time=   0.3s\n",
            "[CV 1/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.600 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.610 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.597 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.602 total time=   0.0s\n",
            "[CV 5/5] END C=0.01, penalty=l2, solver=liblinear;, score=0.595 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.594 total time=   0.2s\n",
            "[CV 2/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.606 total time=   0.2s\n",
            "[CV 3/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.594 total time=   0.3s\n",
            "[CV 4/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.594 total time=   0.3s\n",
            "[CV 5/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.592 total time=   0.2s\n",
            "[CV 1/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.760 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.766 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.774 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.770 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.773 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.761 total time=   0.4s\n",
            "[CV 2/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.764 total time=   0.6s\n",
            "[CV 3/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.773 total time=   0.7s\n",
            "[CV 4/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.769 total time=   0.4s\n",
            "[CV 5/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.773 total time=   0.8s\n",
            "[CV 1/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.788 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.792 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.797 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.792 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.787 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.788 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.791 total time=   0.2s\n",
            "[CV 3/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.797 total time=   0.2s\n",
            "[CV 4/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.791 total time=   0.3s\n",
            "[CV 5/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.786 total time=   0.2s\n",
            "[CV 1/5] END .C=1, penalty=l1, solver=liblinear;, score=0.836 total time=   0.1s\n",
            "[CV 2/5] END .C=1, penalty=l1, solver=liblinear;, score=0.834 total time=   0.1s\n",
            "[CV 3/5] END .C=1, penalty=l1, solver=liblinear;, score=0.838 total time=   0.1s\n",
            "[CV 4/5] END .C=1, penalty=l1, solver=liblinear;, score=0.845 total time=   0.1s\n",
            "[CV 5/5] END .C=1, penalty=l1, solver=liblinear;, score=0.836 total time=   0.2s\n",
            "[CV 1/5] END ......C=1, penalty=l1, solver=saga;, score=0.836 total time=   3.3s\n",
            "[CV 2/5] END ......C=1, penalty=l1, solver=saga;, score=0.834 total time=   2.0s\n",
            "[CV 3/5] END ......C=1, penalty=l1, solver=saga;, score=0.838 total time=   2.3s\n",
            "[CV 4/5] END ......C=1, penalty=l1, solver=saga;, score=0.845 total time=   2.3s\n",
            "[CV 5/5] END ......C=1, penalty=l1, solver=saga;, score=0.836 total time=   2.2s\n",
            "[CV 1/5] END .C=1, penalty=l2, solver=liblinear;, score=0.830 total time=   0.1s\n",
            "[CV 2/5] END .C=1, penalty=l2, solver=liblinear;, score=0.833 total time=   0.1s\n",
            "[CV 3/5] END .C=1, penalty=l2, solver=liblinear;, score=0.838 total time=   0.1s\n",
            "[CV 4/5] END .C=1, penalty=l2, solver=liblinear;, score=0.843 total time=   0.1s\n",
            "[CV 5/5] END .C=1, penalty=l2, solver=liblinear;, score=0.839 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, penalty=l2, solver=saga;, score=0.831 total time=   0.2s\n",
            "[CV 2/5] END ......C=1, penalty=l2, solver=saga;, score=0.833 total time=   0.2s\n",
            "[CV 3/5] END ......C=1, penalty=l2, solver=saga;, score=0.838 total time=   0.2s\n",
            "[CV 4/5] END ......C=1, penalty=l2, solver=saga;, score=0.843 total time=   0.2s\n",
            "[CV 5/5] END ......C=1, penalty=l2, solver=saga;, score=0.839 total time=   0.3s\n",
            "[CV 1/5] END C=10, penalty=l1, solver=liblinear;, score=0.828 total time=   0.2s\n",
            "[CV 2/5] END C=10, penalty=l1, solver=liblinear;, score=0.833 total time=   0.2s\n",
            "[CV 3/5] END C=10, penalty=l1, solver=liblinear;, score=0.828 total time=   0.3s\n",
            "[CV 4/5] END C=10, penalty=l1, solver=liblinear;, score=0.833 total time=   0.3s\n",
            "[CV 5/5] END C=10, penalty=l1, solver=liblinear;, score=0.838 total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END .....C=10, penalty=l1, solver=saga;, score=0.827 total time=   6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END .....C=10, penalty=l1, solver=saga;, score=0.832 total time=   6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END .....C=10, penalty=l1, solver=saga;, score=0.829 total time=   6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END .....C=10, penalty=l1, solver=saga;, score=0.834 total time=   6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END .....C=10, penalty=l1, solver=saga;, score=0.838 total time=   6.9s\n",
            "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.833 total time=   0.1s\n",
            "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.834 total time=   0.1s\n",
            "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.830 total time=   0.1s\n",
            "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.839 total time=   0.1s\n",
            "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.840 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, penalty=l2, solver=saga;, score=0.833 total time=   0.6s\n",
            "[CV 2/5] END .....C=10, penalty=l2, solver=saga;, score=0.833 total time=   0.6s\n",
            "[CV 3/5] END .....C=10, penalty=l2, solver=saga;, score=0.830 total time=   0.6s\n",
            "[CV 4/5] END .....C=10, penalty=l2, solver=saga;, score=0.838 total time=   0.5s\n",
            "[CV 5/5] END .....C=10, penalty=l2, solver=saga;, score=0.841 total time=   0.6s\n",
            "\u001b[91m \n",
            "\n",
            "Best hyperparamaters for Logistic Regression:  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'} \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have identified the best model, make predictions on the validation set:\n",
        "y_pred_log_reg = best_lr_model.predict(lr_val_x)\n",
        "\n",
        "# Now report the results utilizing the data's confusion matrix:\n",
        "lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(lr_val_y, y_pred_log_reg).ravel()\n",
        "\n",
        "# Calculating precision, recall, and f1 using equations from Lecture 9 slides: *making sure to avoid undefined results\n",
        "lr_accuracy = (lr_tp+lr_tn)/(lr_tp+lr_fn+lr_tn+lr_fp)\n",
        "lr_precision = lr_tp / (lr_tp+lr_fp) if (lr_tp + lr_fp) > 0 else 0\n",
        "lr_recall = lr_tp / (lr_tp+lr_fn) if (lr_tp + lr_fn) > 0 else 0\n",
        "lr_f1_macro = f1_score(lr_val_y, y_pred_log_reg, average='macro')\n",
        "\n",
        "# Print results:\n",
        "print(\"\\033[94m\", \"Results for Logistic Regression classifier:\\n\")\n",
        "print(\"Accuracy: \", lr_accuracy)\n",
        "print(\"Precision: \", lr_precision)\n",
        "print(\"Recall: \", lr_recall)\n",
        "print(\"\\nF1 Macro: \", lr_f1_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktD1JsF2PI85",
        "outputId": "253a741c-7b8b-4877-9e3f-0cb81211c78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m Results for Logistic Regression classifier:\n",
            "\n",
            "Accuracy:  0.84975\n",
            "Precision:  0.8315488936473947\n",
            "Recall:  0.761437908496732\n",
            "\n",
            "F1 Macro:  0.8381933547680023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Model 2, Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "Tp1BUWYweEFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following the example notebook at the end of Lecture 12, now utilize a vectorizer to assign numerical values to reviewText:\n",
        "# Initalize vectorizer for SVM:\n",
        "svm_vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=5000)\n",
        "\n",
        "# Fit vectorizer and transform text into features\n",
        "svm_train_features = svm_vectorizer.fit_transform(amazon_train_data['combinedData'].tolist())\n",
        "\n",
        "# Now split into training and validation sets:\n",
        "svm_train_x,svm_val_x,svm_train_y,svm_val_y = train_test_split(svm_train_features, amazon_train_data['label'], test_size=0.2, random_state=4738)"
      ],
      "metadata": {
        "id": "iB1j830YjuhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model using SVM\n",
        "svm = LinearSVC(max_iter=1000)\n",
        "\n",
        "# Define parameter grid, basing off of SVC API documentation\n",
        "param_grid_svm = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Each of the values in Cs describes the inverse of regularization strength\n",
        "    'loss': ['hinge', 'squared_hinge'],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Grid search parameters using 5-fold cross-validation and apply to training set\n",
        "grid_svm = GridSearchCV(svm, param_grid_svm, cv=5, verbose=5, scoring='f1_macro', error_score=0.0)  # cv = int or cross-validation generator\n",
        "grid_svm.fit(svm_train_x, svm_train_y)\n",
        "\n",
        "best_svm_model = grid_svm.best_estimator_\n",
        "print(\"\\033[91m\", \"\\n\\nBest hyperparamaters for SVM: \", grid_svm.best_params_, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtvjT1K-eLl4",
        "outputId": "3e2a1fdd-0191-47e9-a0a6-efad2080446c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV 1/5] END ....C=0.01, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END ....C=0.01, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END ....C=0.01, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END ....C=0.01, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END ....C=0.01, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END ....C=0.01, loss=hinge, penalty=l2;, score=0.570 total time=   0.0s\n",
            "[CV 2/5] END ....C=0.01, loss=hinge, penalty=l2;, score=0.571 total time=   0.0s\n",
            "[CV 3/5] END ....C=0.01, loss=hinge, penalty=l2;, score=0.563 total time=   0.0s\n",
            "[CV 4/5] END ....C=0.01, loss=hinge, penalty=l2;, score=0.563 total time=   0.0s\n",
            "[CV 5/5] END ....C=0.01, loss=hinge, penalty=l2;, score=0.575 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, loss=squared_hinge, penalty=l1;, score=0.675 total time=   0.0s\n",
            "[CV 2/5] END C=0.01, loss=squared_hinge, penalty=l1;, score=0.663 total time=   0.0s\n",
            "[CV 3/5] END C=0.01, loss=squared_hinge, penalty=l1;, score=0.662 total time=   0.0s\n",
            "[CV 4/5] END C=0.01, loss=squared_hinge, penalty=l1;, score=0.653 total time=   0.1s\n",
            "[CV 5/5] END C=0.01, loss=squared_hinge, penalty=l1;, score=0.668 total time=   0.0s\n",
            "[CV 1/5] END C=0.01, loss=squared_hinge, penalty=l2;, score=0.753 total time=   0.1s\n",
            "[CV 2/5] END C=0.01, loss=squared_hinge, penalty=l2;, score=0.756 total time=   0.1s\n",
            "[CV 3/5] END C=0.01, loss=squared_hinge, penalty=l2;, score=0.743 total time=   0.1s\n",
            "[CV 4/5] END C=0.01, loss=squared_hinge, penalty=l2;, score=0.746 total time=   0.1s\n",
            "[CV 5/5] END C=0.01, loss=squared_hinge, penalty=l2;, score=0.759 total time=   0.1s\n",
            "[CV 1/5] END .....C=0.1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END .....C=0.1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END .....C=0.1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END .....C=0.1, loss=hinge, penalty=l2;, score=0.798 total time=   0.0s\n",
            "[CV 2/5] END .....C=0.1, loss=hinge, penalty=l2;, score=0.795 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, loss=hinge, penalty=l2;, score=0.782 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, loss=hinge, penalty=l2;, score=0.788 total time=   0.0s\n",
            "[CV 5/5] END .....C=0.1, loss=hinge, penalty=l2;, score=0.796 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, loss=squared_hinge, penalty=l1;, score=0.819 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, loss=squared_hinge, penalty=l1;, score=0.817 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, loss=squared_hinge, penalty=l1;, score=0.807 total time=   0.2s\n",
            "[CV 4/5] END C=0.1, loss=squared_hinge, penalty=l1;, score=0.815 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, loss=squared_hinge, penalty=l1;, score=0.820 total time=   0.2s\n",
            "[CV 1/5] END C=0.1, loss=squared_hinge, penalty=l2;, score=0.852 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, loss=squared_hinge, penalty=l2;, score=0.853 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, loss=squared_hinge, penalty=l2;, score=0.842 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, loss=squared_hinge, penalty=l2;, score=0.851 total time=   0.1s\n",
            "[CV 5/5] END C=0.1, loss=squared_hinge, penalty=l2;, score=0.854 total time=   0.1s\n",
            "[CV 1/5] END .......C=1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END .......C=1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END .......C=1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END .......C=1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END .......C=1, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END .......C=1, loss=hinge, penalty=l2;, score=0.855 total time=   0.2s\n",
            "[CV 2/5] END .......C=1, loss=hinge, penalty=l2;, score=0.855 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, loss=hinge, penalty=l2;, score=0.837 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, loss=hinge, penalty=l2;, score=0.852 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, loss=hinge, penalty=l2;, score=0.860 total time=   0.1s\n",
            "[CV 1/5] END C=1, loss=squared_hinge, penalty=l1;, score=0.848 total time=   1.0s\n",
            "[CV 2/5] END C=1, loss=squared_hinge, penalty=l1;, score=0.844 total time=   1.0s\n",
            "[CV 3/5] END C=1, loss=squared_hinge, penalty=l1;, score=0.833 total time=   0.9s\n",
            "[CV 4/5] END C=1, loss=squared_hinge, penalty=l1;, score=0.845 total time=   1.2s\n",
            "[CV 5/5] END C=1, loss=squared_hinge, penalty=l1;, score=0.851 total time=   1.3s\n",
            "[CV 1/5] END C=1, loss=squared_hinge, penalty=l2;, score=0.850 total time=   0.2s\n",
            "[CV 2/5] END C=1, loss=squared_hinge, penalty=l2;, score=0.850 total time=   0.2s\n",
            "[CV 3/5] END C=1, loss=squared_hinge, penalty=l2;, score=0.833 total time=   0.2s\n",
            "[CV 4/5] END C=1, loss=squared_hinge, penalty=l2;, score=0.846 total time=   0.2s\n",
            "[CV 5/5] END C=1, loss=squared_hinge, penalty=l2;, score=0.855 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END ......C=10, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END ......C=10, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END ......C=10, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END ......C=10, loss=hinge, penalty=l1;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, loss=hinge, penalty=l2;, score=0.828 total time=   1.4s\n",
            "[CV 2/5] END ......C=10, loss=hinge, penalty=l2;, score=0.825 total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END ......C=10, loss=hinge, penalty=l2;, score=0.825 total time=   1.0s\n",
            "[CV 4/5] END ......C=10, loss=hinge, penalty=l2;, score=0.817 total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END ......C=10, loss=hinge, penalty=l2;, score=0.841 total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END C=10, loss=squared_hinge, penalty=l1;, score=0.798 total time=  10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END C=10, loss=squared_hinge, penalty=l1;, score=0.807 total time=   9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END C=10, loss=squared_hinge, penalty=l1;, score=0.788 total time=   9.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END C=10, loss=squared_hinge, penalty=l1;, score=0.800 total time=   9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END C=10, loss=squared_hinge, penalty=l1;, score=0.814 total time=   9.2s\n",
            "[CV 1/5] END C=10, loss=squared_hinge, penalty=l2;, score=0.824 total time=   0.3s\n",
            "[CV 2/5] END C=10, loss=squared_hinge, penalty=l2;, score=0.821 total time=   0.3s\n",
            "[CV 3/5] END C=10, loss=squared_hinge, penalty=l2;, score=0.802 total time=   0.3s\n",
            "[CV 4/5] END C=10, loss=squared_hinge, penalty=l2;, score=0.806 total time=   0.3s\n",
            "[CV 5/5] END C=10, loss=squared_hinge, penalty=l2;, score=0.829 total time=   0.3s\n",
            "\u001b[91m \n",
            "\n",
            "Best hyperparamaters for SVM:  {'C': 1, 'loss': 'hinge', 'penalty': 'l2'} \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "20 fits failed out of a total of 80.\n",
            "The score on these train-test partitions for these parameters will be set to 0.0.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "20 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_classes.py\", line 317, in fit\n",
            "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1214, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1046, in _get_liblinear_solver_type\n",
            "    raise ValueError(\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have identified the best model, make predictions on the validation set:\n",
        "y_pred_svm = best_svm_model.predict(svm_val_x)\n",
        "\n",
        "# Now report the results utilizing the data's confusion matrix:\n",
        "svm_tn, svm_fp, svm_fn, svm_tp = confusion_matrix(svm_val_y, y_pred_svm).ravel()\n",
        "\n",
        "# Calculating precision, recall, and f1 using equations from Lecture 9 slides: *making sure to avoid undefined results\n",
        "svm_accuracy = (svm_tp+svm_tn)/(svm_tp+svm_fn+svm_tn+svm_fp)\n",
        "svm_precision = svm_tp / (svm_tp+svm_fp) if (svm_tp + svm_fp) > 0 else 0\n",
        "svm_recall = svm_tp / (svm_tp+svm_fn) if (svm_tp + svm_fn) > 0 else 0\n",
        "svm_f1_macro = f1_score(svm_val_y, y_pred_svm, average='macro')\n",
        "\n",
        "# Print results:\n",
        "print(\"\\033[94m\", \"Results for SVM classifier:\\n\")\n",
        "print(\"Accuracy: \", svm_accuracy)\n",
        "print(\"Precision: \", svm_precision)\n",
        "print(\"Recall: \", svm_recall)\n",
        "print(\"\\nF1 Macro: \", svm_f1_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrKh3t68eVo_",
        "outputId": "155caba9-942c-4d20-c17f-1c36506a4257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m Results for SVM classifier:\n",
            "\n",
            "Accuracy:  0.86\n",
            "Precision:  0.8443824145150035\n",
            "Recall:  0.7821590174531351\n",
            "\n",
            "F1 Macro:  0.8502633760260969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Model 3, Naive Bayes"
      ],
      "metadata": {
        "id": "WaZ_CnWxzTTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following the example notebook at the end of Lecture 12, now utilize a vectorizer to assign numerical values to reviewText:\n",
        "# Initalize vectorizer for :\n",
        "nb_vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=1000)\n",
        "\n",
        "# Fit vectorizer and transform text into features\n",
        "nb_train_features = nb_vectorizer.fit_transform(amazon_train_data['combinedData'].tolist())\n",
        "\n",
        "# Now split into training and validation sets:\n",
        "nb_train_x,nb_val_x,nb_train_y,nb_val_y = train_test_split(nb_train_features, amazon_train_data['label'], test_size=0.2, random_state=24335)"
      ],
      "metadata": {
        "id": "CPu9m9CJx6wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model using Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Define parameter grid, basing off of MultinomialNB API documentation\n",
        "param_grid_nb = {\n",
        "    'alpha': [0.01, 0.1, 0.5, 1, 5, 10]  #  Additive (Laplace/Lidstone) smoothing parameter\n",
        "}\n",
        "\n",
        "# Grid search parameters using 5-fold cross-validation and apply to training set\n",
        "grid_nb = GridSearchCV(nb, param_grid_nb, cv=5, verbose=5, scoring='accuracy', error_score=0.0)  # cv = int or cross-validation generator\n",
        "grid_nb.fit(nb_train_x, nb_train_y)\n",
        "\n",
        "best_nb_model = grid_nb.best_estimator_\n",
        "print(\"\\033[91m\", \"\\n\\nBest hyperparamaters for Naive Bayes: \", grid_nb.best_params_, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9lO3C4Exgu5",
        "outputId": "7bceb423-2cd2-4e91-d70e-eee7c48002ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV 1/5] END ........................alpha=0.01;, score=0.811 total time=   0.0s\n",
            "[CV 2/5] END ........................alpha=0.01;, score=0.802 total time=   0.0s\n",
            "[CV 3/5] END ........................alpha=0.01;, score=0.809 total time=   0.0s\n",
            "[CV 4/5] END ........................alpha=0.01;, score=0.807 total time=   0.0s\n",
            "[CV 5/5] END ........................alpha=0.01;, score=0.816 total time=   0.0s\n",
            "[CV 1/5] END .........................alpha=0.1;, score=0.810 total time=   0.0s\n",
            "[CV 2/5] END .........................alpha=0.1;, score=0.802 total time=   0.0s\n",
            "[CV 3/5] END .........................alpha=0.1;, score=0.809 total time=   0.0s\n",
            "[CV 4/5] END .........................alpha=0.1;, score=0.807 total time=   0.0s\n",
            "[CV 5/5] END .........................alpha=0.1;, score=0.816 total time=   0.0s\n",
            "[CV 1/5] END .........................alpha=0.5;, score=0.809 total time=   0.0s\n",
            "[CV 2/5] END .........................alpha=0.5;, score=0.800 total time=   0.0s\n",
            "[CV 3/5] END .........................alpha=0.5;, score=0.807 total time=   0.0s\n",
            "[CV 4/5] END .........................alpha=0.5;, score=0.808 total time=   0.0s\n",
            "[CV 5/5] END .........................alpha=0.5;, score=0.815 total time=   0.0s\n",
            "[CV 1/5] END ...........................alpha=1;, score=0.808 total time=   0.0s\n",
            "[CV 2/5] END ...........................alpha=1;, score=0.799 total time=   0.0s\n",
            "[CV 3/5] END ...........................alpha=1;, score=0.806 total time=   0.0s\n",
            "[CV 4/5] END ...........................alpha=1;, score=0.808 total time=   0.0s\n",
            "[CV 5/5] END ...........................alpha=1;, score=0.815 total time=   0.0s\n",
            "[CV 1/5] END ...........................alpha=5;, score=0.797 total time=   0.0s\n",
            "[CV 2/5] END ...........................alpha=5;, score=0.786 total time=   0.0s\n",
            "[CV 3/5] END ...........................alpha=5;, score=0.798 total time=   0.0s\n",
            "[CV 4/5] END ...........................alpha=5;, score=0.799 total time=   0.0s\n",
            "[CV 5/5] END ...........................alpha=5;, score=0.807 total time=   0.0s\n",
            "[CV 1/5] END ..........................alpha=10;, score=0.784 total time=   0.0s\n",
            "[CV 2/5] END ..........................alpha=10;, score=0.773 total time=   0.0s\n",
            "[CV 3/5] END ..........................alpha=10;, score=0.783 total time=   0.0s\n",
            "[CV 4/5] END ..........................alpha=10;, score=0.786 total time=   0.0s\n",
            "[CV 5/5] END ..........................alpha=10;, score=0.795 total time=   0.0s\n",
            "\u001b[91m \n",
            "\n",
            "Best hyperparamaters for Naive Bayes:  {'alpha': 0.01} \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have identified the best model, make predictions on the validation set:\n",
        "y_pred_nb = best_nb_model.predict(nb_val_x)\n",
        "\n",
        "# Now report the results utilizing the data's confusion matrix:\n",
        "nb_tn, nb_fp, nb_fn, nb_tp = confusion_matrix(nb_val_y, y_pred_nb).ravel()\n",
        "\n",
        "# Calculating precision, recall, and f1 using equations from Lecture 9 slides: *making sure to avoid undefined results\n",
        "nb_accuracy = (nb_tp+nb_tn)/(nb_tp+nb_fn+nb_tn+nb_fp)\n",
        "nb_precision = nb_tp / (nb_tp+nb_fp) if (nb_tp + nb_fp) > 0 else 0\n",
        "nb_recall = nb_tp / (nb_tp+nb_fn) if (nb_tp + nb_fn) > 0 else 0\n",
        "nb_f1_macro = f1_score(nb_val_y, y_pred_nb, average='macro')\n",
        "\n",
        "# Print results:\n",
        "print(\"\\033[94m\", \"Results for Naive Bayes classifier:\\n\")\n",
        "print(\"Accuracy: \", nb_accuracy)\n",
        "print(\"Precision: \", nb_precision)\n",
        "print(\"Recall: \", nb_recall)\n",
        "print(\"\\nF1 Macro: \", nb_f1_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEdgIC3NzBOB",
        "outputId": "b58b9495-a8be-4e33-c3bc-5da88990fe47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m Results for Naive Bayes classifier:\n",
            "\n",
            "Accuracy:  0.8075\n",
            "Precision:  0.9146968139773896\n",
            "Recall:  0.5643627140139506\n",
            "\n",
            "F1 Macro:  0.7783774060082749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'SVM', 'Naive Bayes'],\n",
        "    'Precision': [lr_precision, svm_precision, nb_precision],\n",
        "    'Recall': [lr_recall, svm_recall, nb_recall],\n",
        "    'F1 Macro': [lr_f1_macro, svm_f1_macro, nb_f1_macro]\n",
        "})\n",
        "results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kuZESWsL50yf",
        "outputId": "5b8ea6b5-818b-43fe-9483-be3429959afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model  Precision    Recall  F1 Macro\n",
              "0  Logistic Regression   0.831549  0.761438  0.838193\n",
              "1                  SVM   0.844382  0.782159  0.850263\n",
              "2          Naive Bayes   0.914697  0.564363  0.778377"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d253e3d-0163-44f5-bd2a-39bf2580623b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.831549</td>\n",
              "      <td>0.761438</td>\n",
              "      <td>0.838193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.844382</td>\n",
              "      <td>0.782159</td>\n",
              "      <td>0.850263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.914697</td>\n",
              "      <td>0.564363</td>\n",
              "      <td>0.778377</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d253e3d-0163-44f5-bd2a-39bf2580623b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d253e3d-0163-44f5-bd2a-39bf2580623b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d253e3d-0163-44f5-bd2a-39bf2580623b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1707aa2d-a895-44ff-9c0e-dd89dffc4c9a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1707aa2d-a895-44ff-9c0e-dd89dffc4c9a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1707aa2d-a895-44ff-9c0e-dd89dffc4c9a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Logistic Regression\",\n          \"SVM\",\n          \"Naive Bayes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04476306268345684,\n        \"min\": 0.8315488936473947,\n        \"max\": 0.9146968139773896,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8315488936473947,\n          0.8443824145150035,\n          0.9146968139773896\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12021038947652195,\n        \"min\": 0.5643627140139506,\n        \"max\": 0.7821590174531351,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.761437908496732,\n          0.7821590174531351,\n          0.5643627140139506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0384950772277019,\n        \"min\": 0.7783774060082749,\n        \"max\": 0.8502633760260969,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8381933547680023,\n          0.8502633760260969,\n          0.7783774060082749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that SVM has been identified as the best model, use it to create predictions on the test data:\n",
        "# Reading the data:\n",
        "amazon_test_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/hw4-test-new.csv')\n",
        "\n",
        "# Combine reviewText and summary data (dropping any empty review rows):\n",
        "amazon_test_data['combinedData'] = amazon_test_data['reviewText'].fillna(\"\") + \" \" + amazon_test_data['summary'].fillna(\"\")\n",
        "\n",
        "# Apply text processing to combined test data:\n",
        "amazon_test_data['combinedData'] = amazon_test_data['combinedData'].apply(process_text)\n",
        "\n",
        "# Fit vectorizer and transform text into features\n",
        "test_features = svm_vectorizer.fit_transform(amazon_test_data['combinedData'].tolist())\n",
        "\n",
        "# Make predictions on the test set:\n",
        "test_pred = best_svm_model.predict(test_features)\n",
        "\n",
        "# Create a column demonstrating the prediction data in the test file\n",
        "amazon_test_data['predictionLabels'] = test_pred\n",
        "\n",
        "# Output results to csv:\n",
        "submission_df = amazon_test_data[['id', 'predictionLabels']]\n",
        "submission_df.to_csv('/content/drive/My Drive/Colab Notebooks/hw4-test-predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "pU89BOod668h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Classification with Machine Learning Models\n",
        "\n",
        "For this part, your goal is to measure the performance of an open-source large language model\n",
        "of the review classification task and report their performance. For this task, you do not have to\n",
        "train your model. You will apply different in-context-learning/ prompting approaches on the\n",
        "provided test set and report the LLMs' precision, recall, and macro F1-score. Refer to this guide\n",
        "(https://www.promptingguide.ai/techniques) and X-hour materials provided in the class for an\n",
        "overview of different prompting techniques"
      ],
      "metadata": {
        "id": "n66AQZ1KLvuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Following sample code provided in x-hour -- imports:\n",
        "\n",
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install -U langchain-community\n",
        "\n",
        "import os, json\n",
        "from langchain_community.llms import HuggingFaceEndpoint\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "\n",
        "import random"
      ],
      "metadata": {
        "id": "Xq1N4k-xzn_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load token:\n",
        "#hf_token = 
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=hf_token\n",
        "\n",
        "# Loading the testing model:\n",
        "model_name = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
        "\n",
        "# First load in new test data and extract true labels:\n",
        "llm_test_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/hw4-llm-test-part2-new.csv')\n",
        "llm_labels = llm_test_data['label'].tolist()\n",
        "\n",
        "# Also combine summary and reviewText data for added context and text process:\n",
        "llm_test_data['combinedData'] = llm_test_data['reviewText'].fillna(\"\") + \" \" + llm_test_data['summary'].fillna(\"\")\n",
        "llm_test_data['combinedData'] = llm_test_data['combinedData'].apply(process_text)\n",
        "\n",
        "# Define prompt template:\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['instruction', 'context'],\n",
        "    template = '''\n",
        "    {instruction}\n",
        "\n",
        "    {context}\n",
        "    '''\n",
        ")"
      ],
      "metadata": {
        "id": "t56nckqsKZTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMs outputs are often unstable and contain extra information -- define a parser function to clearly get the output\n",
        "def extract_label(output):\n",
        "  # First check if an output exists:\n",
        "  if not output:\n",
        "    # If an output cannot be determined, randomly choose\n",
        "    return random.choice([0, 1])\n",
        "\n",
        "  # If an output exists:\n",
        "  output = output.lower().strip()  # Parse for maximum efficiency\n",
        "\n",
        "  if 'low-star' in output:\n",
        "    return 0\n",
        "  elif 'high-star' in output:\n",
        "    return 1\n",
        "  else:\n",
        "    return random.choice([0, 1])\n",
        "\n",
        "# Alternate parsing function\n",
        "\"\"\"\n",
        "def extract_label(output):\n",
        "  # Convert the output to lowercase to make the search case-insensitive\n",
        "    output = output.lower()\n",
        "\n",
        "    # Check for \"high-star\" and \"low-star\" and *return the one that appears first*\n",
        "    high_star_index = output.find(\"high-star\")\n",
        "    low_star_index = output.find(\"low-star\")\n",
        "\n",
        "    if high_star_index == -1 and low_star_index == -1:\n",
        "        return 0  # If neither label is found, return low-star\n",
        "\n",
        "    # If only \"high-star\" is found\n",
        "    if high_star_index != -1 and (low_star_index == -1 or high_star_index < low_star_index):\n",
        "        return 1\n",
        "\n",
        "    # If only \"low-star\" is found or \"low-star\" appears first\n",
        "    if low_star_index != -1 and (high_star_index == -1 or low_star_index < high_star_index):\n",
        "        return 0\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zbZ9C-HU-bZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Model 1, Zero Shot"
      ],
      "metadata": {
        "id": "Rmq5Gw1GcX34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zs_model = HuggingFaceEndpoint(repo_id= model_name, temperature=0.7, max_new_tokens=100)\n",
        "zs_prompt_chain = prompt_template | zs_model | StrOutputParser()\n",
        "\n",
        "# Following example llm code handout -- Zero-Shot: Only task description (TD)\n",
        "zs_task_instruction = \"\"\"\n",
        "Read the review and output if it is 'high-star' or 'low-star'.\n",
        "\"\"\"\n",
        "\n",
        "#demonstrations = \"\"\"\"\"\"\n",
        "\n",
        "# Create an array to store predicted_labels based off of model\n",
        "zs_predicted_labels = []\n",
        "\n",
        "print(\"Zero Shot data:\\n\")\n",
        "\n",
        "# Now loop through each row of data and apply the LLM:\n",
        "for review in llm_test_data['combinedData'][:15]:\n",
        "  print(\"Review: \", review)\n",
        "\n",
        "  zero_shot_input = {\n",
        "        'instruction': zs_task_instruction,\n",
        "        'context': f\"Review: {review}\"\n",
        "    }\n",
        "\n",
        "  try:\n",
        "    # Get model output\n",
        "    zero_shot_output = zs_prompt_chain.invoke(zero_shot_input)\n",
        "    print(\"Unextracted: \", zero_shot_output)\n",
        "\n",
        "    # Extract the label from the model output for clarity\n",
        "    zs_extracted_label = extract_label(zero_shot_output)\n",
        "    print(\"Extracted: \", zs_extracted_label)\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    # Append extracted label to the list\n",
        "    zs_predicted_labels.append(zs_extracted_label)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3g1i1x4bs8-",
        "outputId": "f57aec1a-7b12-4604-a77f-12e446d14987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero Shot data:\n",
            "\n",
            "Review:  cheap didn t last   year an i only used it for gaming one star\n",
            "Unextracted:  \n",
            "    Output: low-star\n",
            "\n",
            "    Review: this is the best headset i have ever used, the sound quality is amazing and it has a lot of features an ten stars\n",
            "    \n",
            "    Output: high-star\n",
            "\n",
            "    Review: i love the headset but the mic doesn t work properly sometimes three stars\n",
            "    \n",
            "    Output: medium-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  work great in my m  gbb  v tac bbs valken tactical     g bottle\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  love this case       durable and low profile five stars\n",
            "Unextracted:  ------------------------------------------------------------\n",
            "    Output: high-star\n",
            "\n",
            "    Review: the case is cheap and flimsy one star\n",
            "    ------------------------------------------------------------\n",
            "    Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  all we have acquired smartphone blu brand  we know that we are excellent devices  particularly recommend  we know that we are excellent devices  particularly recommend\n",
            "Unextracted:  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  not attached yet   looks good   looks like it will work well  looks good   looks like it will work well\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  the case itself is nice  but the colors on the screen do not match the colors of the actual product   the aluminum portion is not what i would call red especially compared to the other parts of the case   it is a totally different color  it looks more like a rose color or mauve color to me and in different light can even take on a sort of rust color   i will keep the case  but will continue to look for something that is the color i wanted  aluminum plate is not red\n",
            "Unextracted:  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  now i understand that the lighter roasts  such as lavazza  have the most caffeine   i went back to a darker bean  had me jumping\n",
            "Unextracted:   output: high-star\n",
            "\n",
            "    Review: the coffee was bitter and i could not finish my cup   i prefer a medium roast\n",
            "     output: low-star\n",
            "\n",
            "    Review: the coffee was too strong   i couldnt sleep all night\n",
            "     output: high-star\n",
            "\n",
            "    Review: the coffee was weak and lacked flavor   i would not buy it again\n",
            "     output: low-star\n",
            "\n",
            "    Review: i love the dark roast coffee   it\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  several issues with these mirrors  first the screw that holds the mirror to the stem month hold so the mirror just spins in circles  blue or red locktite will not hold  so i used jb welding to secure the post in place  second  the post for the adapters strip out and the whole mirror vibrates and starts spinning  blue and red locktite will not hold this in place so again i used jb welding to secure the post in the mirror  finally  after riding around and pressing the mirror back into place a small fracture developed allowing corrosion into the stem  while riding the stem snapped in half  so i am using jb welding to see if i can put it back together  buy these    and some jb weld\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  it looks good  but it has been falling apart since i first put it up  most of where the horizontal pieces meet the vertical pieces have come unglued with the slightest breeze  so i ve been stitching back together every day  at least i have a pattern to work from and didn t have to design it myself  fun design doesn t hold up to the wind\n",
            "Unextracted:  \n",
            "    Output: low-star\n",
            "\n",
            "Here's the Python code for the above output:\n",
            "\n",
            "```python\n",
            "def read_review(review):\n",
            "    words = review.split()\n",
            "    if \"high-star\" in words or \"great\" in words or \"excellent\" in words:\n",
            "        return \"high-star\"\n",
            "    elif \"low-star\" in words or \"poor\" in words or \"bad\" in words:\n",
            "\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  actually i ordered this product by mistake   i wanted simply straight bands not knowing that loop bands are a different item entirely  i doubt if i ll use them but the price was reasonable and the quality is excellent  so i decided to keep them  maybe my kids can use them   i m too old for these  they are so dense i can hardly get them to stretch  top quality\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  looks great  poor lifespan buy extras   the lifespan is very poor\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  too small for the phone   it is as if the phone is one eight inch too wide for it   sides did not fully wrap to the front   we went to the verizon store and bought theirs and they are working great  does not fit the icon\n",
            "Unextracted:  \n",
            "Output: low-star\n",
            "\n",
            "\n",
            "    Review: I am really enjoying the case! I love the color and the way it fits perfectly on my phone. It is snug and feels secure, yet not too tight. The buttons are easy to press and the cutouts for the camera and speakers are well-placed. I highly recommend this case!\n",
            "\n",
            "     Output: high-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  once again a great product from rcbs four stars\n",
            "Unextracted:  \n",
            "    Output: high-star\n",
            "\n",
            "    Review: this is a terrible product, I don't recommend it to anyone, zero stars\n",
            "    \n",
            "    Output: low-star\n",
            "\n",
            "    Review: I think this product is average, I would rate it three stars\n",
            "    \n",
            "    Output: medium-star\n",
            "\n",
            "    Review: I have not tried this product yet, but it looks good, I'd give it four stars\n",
            "    \n",
            "    Output: high-star\n",
            "\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  i ve read about half of the reviews of this cd that are posted here and i have listened to the cd at least    times  i don t understand those who dismiss down the road because it is not moondance or astral weeks  of course it isn t  but can t those critics hear that the spirit of those long ago days still haunts van morrison s soul \n",
            "personally  i think that this is van s best  most well rounded album since too long in exile  it has all the joyful bounce of street choir and moondance as well as a taste of his introspective mid period moods \n",
            "my favorites are talk is cheap  choppin  wood  ok  the background vocals are obnoxious but its still a great song   the maligned all work and no play  its those background vocals again   the soulful whatever happened to pj proby  only a dream  and evening shadows \n",
            "that last merits special mention  originally written as an instrumental by   s soft jazz pioneer acker bilk  van adds lyrics to evening shadows which really fit the music then brings bilk aboard to do a clarinet solo on his own music brought to life  tremendous \n",
            "about the only song i don t care for is van s rendition of georgia on my mind  but then that song has never been a favorite anyhow \n",
            "i m with the reviewer who said he did not care if van broke no new ground  he has given the world forty years of wonderful music and its hard to see what new ground he could possibly break  i highly recommend down the road to one and all  all the joy and beauty of days gone by\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  iconic  megadeth s crowning achievement  i first purchased this cd at the      release after seeing video on mtv  then saw them live at cow palace sf  during the countdown tour and have purchased many megadeth cd s since then  anyway this mobile fidelity      stereo only  right left sub  release remastered with dave mustaine himself is worth every penny of         the jewel case with pop up for cd is first i have seen  love it  the liner notes by mustaine are great  i am usually not a big fan of bonus tracks or demo s etc  but these   bonus tracks are as good as any on the entire cd and i am glad mustaine added them \n",
            "thanks mobile fidelity and megadeth  countdown to extinction explicit lyrics  limited edition  extra tracks\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now report the results utilizing the data's confusion matrix:\n",
        "zs_tn, zs_fp, zs_fn, zs_tp = confusion_matrix(llm_labels[:15], zs_predicted_labels).ravel()\n",
        "\n",
        "# Calculating precision, recall, and f1 using equations from Lecture 9 slides: *making sure to avoid undefined results\n",
        "zs_accuracy = (zs_tp+zs_tn)/(zs_tp+zs_fn+zs_tn+zs_fp)\n",
        "zs_precision = zs_tp / (zs_tp+zs_fp) if (zs_tp + zs_fp) > 0 else 0\n",
        "zs_recall = zs_tp / (zs_tp+zs_fn) if (zs_tp + zs_fn) > 0 else 0\n",
        "zs_f1_macro = f1_score(llm_labels[:15], zs_predicted_labels, average='macro')\n",
        "\n",
        "\n",
        "# Print results:\n",
        "print(\"\\033[94m\", \"Results for Zero Shot Model:\\n\")\n",
        "print(\"Accuracy: \", zs_accuracy)\n",
        "print(\"Precision: \", zs_precision)\n",
        "print(\"Recall: \", zs_recall)\n",
        "print(\"\\nF1 Macro: \", zs_f1_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9STdHShd_7Rx",
        "outputId": "739537aa-31e7-44ef-811c-53526b199a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m Results for Zero Shot Model:\n",
            "\n",
            "Accuracy:  0.5333333333333333\n",
            "Precision:  0.6\n",
            "Recall:  0.375\n",
            "\n",
            "F1 Macro:  0.5248868778280543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Model 2, One Shot"
      ],
      "metadata": {
        "id": "TEAhSYY9el23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os_model = HuggingFaceEndpoint(repo_id=model_name, temperature=0.7, max_new_tokens=100)\n",
        "os_prompt_chain = prompt_template | os_model | StrOutputParser()\n",
        "\n",
        "# Following example llm code handout -- One-Shot: TD + one example\n",
        "os_task_instruction = \"\"\"\n",
        "Read the review and classify it as 'high-star' or 'low-star'. Use the provided example as a guide to understand the classification criteria.\n",
        "\"\"\"\n",
        "\n",
        "# The in-context samples for one-shot and few-shot experiments must be taken from the training set\n",
        "os_demonstrations = \"\"\"\n",
        "Example review and output shown below:\n",
        "Review: 'my baby loves this rattle. he can easily grab it and loves the noise. Baby Approved.'\n",
        "Output: high-star\n",
        "\"\"\"\n",
        "\n",
        "# Create an array to store predicted_labels based off of model\n",
        "os_predicted_labels = []\n",
        "\n",
        "print(\"One Shot data:\\n\")\n",
        "# Now loop through each row of data and apply the LLM:\n",
        "for review in llm_test_data['combinedData'][:15]:\n",
        "  print(\"Review: \", review)\n",
        "\n",
        "  one_shot_input = {\n",
        "        'instruction': os_task_instruction,\n",
        "        'context': f\"{os_demonstrations}\\n\\nReview to classify: {review}\"\n",
        "    }\n",
        "\n",
        "  try:\n",
        "    # Get model output\n",
        "    one_shot_output = os_prompt_chain.invoke(one_shot_input)\n",
        "    print(\"Unextracted: \", one_shot_output)\n",
        "\n",
        "    # Extract the label from the model output for clarity\n",
        "    os_extracted_label = extract_label(one_shot_output)\n",
        "    print(\"Extracted: \", os_extracted_label)\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    # Append extracted label to the list\n",
        "    os_predicted_labels.append(os_extracted_label)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3M75phAeuJr",
        "outputId": "30c78504-be17-4d53-9bf1-cd3ad4816cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One Shot data:\n",
            "\n",
            "Review:  cheap didn t last   year an i only used it for gaming one star\n",
            "Unextracted:  \n",
            "Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  work great in my m  gbb  v tac bbs valken tactical     g bottle\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  love this case       durable and low profile five stars\n",
            "Unextracted:  \n",
            "Output: high-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  all we have acquired smartphone blu brand  we know that we are excellent devices  particularly recommend  we know that we are excellent devices  particularly recommend\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  not attached yet   looks good   looks like it will work well  looks good   looks like it will work well\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  the case itself is nice  but the colors on the screen do not match the colors of the actual product   the aluminum portion is not what i would call red especially compared to the other parts of the case   it is a totally different color  it looks more like a rose color or mauve color to me and in different light can even take on a sort of rust color   i will keep the case  but will continue to look for something that is the color i wanted  aluminum plate is not red\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  now i understand that the lighter roasts  such as lavazza  have the most caffeine   i went back to a darker bean  had me jumping\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  several issues with these mirrors  first the screw that holds the mirror to the stem month hold so the mirror just spins in circles  blue or red locktite will not hold  so i used jb welding to secure the post in place  second  the post for the adapters strip out and the whole mirror vibrates and starts spinning  blue and red locktite will not hold this in place so again i used jb welding to secure the post in the mirror  finally  after riding around and pressing the mirror back into place a small fracture developed allowing corrosion into the stem  while riding the stem snapped in half  so i am using jb welding to see if i can put it back together  buy these    and some jb weld\n",
            "Unextracted:  \n",
            "Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  it looks good  but it has been falling apart since i first put it up  most of where the horizontal pieces meet the vertical pieces have come unglued with the slightest breeze  so i ve been stitching back together every day  at least i have a pattern to work from and didn t have to design it myself  fun design doesn t hold up to the wind\n",
            "Unextracted:  \n",
            "Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  actually i ordered this product by mistake   i wanted simply straight bands not knowing that loop bands are a different item entirely  i doubt if i ll use them but the price was reasonable and the quality is excellent  so i decided to keep them  maybe my kids can use them   i m too old for these  they are so dense i can hardly get them to stretch  top quality\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  looks great  poor lifespan buy extras   the lifespan is very poor\n",
            "Unextracted:  \n",
            "Output: low-star\n",
            "\n",
            "\n",
            "Review to classify: this is the best product i've ever bought, it's so comfortable and durable. i would recommend it to anyone looking for a quality product.\n",
            "    \n",
            "Output: high-star\n",
            "\n",
            "\n",
            "Review to classify: I purchased this product and it broke after only a week. I am very disappointed and will not be buying it again.\n",
            "    \n",
            "Output: low-star\n",
            "\n",
            "\n",
            "Review to classify\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  too small for the phone   it is as if the phone is one eight inch too wide for it   sides did not fully wrap to the front   we went to the verizon store and bought theirs and they are working great  does not fit the icon\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  once again a great product from rcbs four stars\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  i ve read about half of the reviews of this cd that are posted here and i have listened to the cd at least    times  i don t understand those who dismiss down the road because it is not moondance or astral weeks  of course it isn t  but can t those critics hear that the spirit of those long ago days still haunts van morrison s soul \n",
            "personally  i think that this is van s best  most well rounded album since too long in exile  it has all the joyful bounce of street choir and moondance as well as a taste of his introspective mid period moods \n",
            "my favorites are talk is cheap  choppin  wood  ok  the background vocals are obnoxious but its still a great song   the maligned all work and no play  its those background vocals again   the soulful whatever happened to pj proby  only a dream  and evening shadows \n",
            "that last merits special mention  originally written as an instrumental by   s soft jazz pioneer acker bilk  van adds lyrics to evening shadows which really fit the music then brings bilk aboard to do a clarinet solo on his own music brought to life  tremendous \n",
            "about the only song i don t care for is van s rendition of georgia on my mind  but then that song has never been a favorite anyhow \n",
            "i m with the reviewer who said he did not care if van broke no new ground  he has given the world forty years of wonderful music and its hard to see what new ground he could possibly break  i highly recommend down the road to one and all  all the joy and beauty of days gone by\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  iconic  megadeth s crowning achievement  i first purchased this cd at the      release after seeing video on mtv  then saw them live at cow palace sf  during the countdown tour and have purchased many megadeth cd s since then  anyway this mobile fidelity      stereo only  right left sub  release remastered with dave mustaine himself is worth every penny of         the jewel case with pop up for cd is first i have seen  love it  the liner notes by mustaine are great  i am usually not a big fan of bonus tracks or demo s etc  but these   bonus tracks are as good as any on the entire cd and i am glad mustaine added them \n",
            "thanks mobile fidelity and megadeth  countdown to extinction explicit lyrics  limited edition  extra tracks\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now report the results utilizing the data's confusion matrix:\n",
        "os_tn, os_fp, os_fn, os_tp = confusion_matrix(llm_labels[:15], os_predicted_labels).ravel()\n",
        "\n",
        "# Calculating precision, recall, and f1 using equations from Lecture 9 slides: *making sure to avoid undefined results\n",
        "os_accuracy = (os_tp+os_tn)/(os_tp+os_fn+os_tn+os_fp)\n",
        "os_precision = os_tp / (os_tp+os_fp) if (os_tp + os_fp) > 0 else 0\n",
        "os_recall = os_tp / (os_tp+os_fn) if (os_tp + os_fn) > 0 else 0\n",
        "os_f1_macro = f1_score(llm_labels[:15], os_predicted_labels, average='macro')\n",
        "\n",
        "\n",
        "# Print results:\n",
        "print(\"\\033[94m\", \"Results for One Shot Model:\\n\")\n",
        "print(\"Accuracy: \", os_accuracy)\n",
        "print(\"Precision: \", os_precision)\n",
        "print(\"Recall: \", os_recall)\n",
        "print(\"\\nF1 Macro: \", os_f1_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwqBo0NUc8m8",
        "outputId": "aeeae85e-f39d-4bb6-bedf-74ede737f07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m Results for One Shot Model:\n",
            "\n",
            "Accuracy:  0.7333333333333333\n",
            "Precision:  0.8333333333333334\n",
            "Recall:  0.625\n",
            "\n",
            "F1 Macro:  0.7321428571428572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Model 3, Few Shot"
      ],
      "metadata": {
        "id": "hVZZh2A6X6Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fs_model = HuggingFaceEndpoint(repo_id=model_name, temperature=0.7, max_new_tokens=100)\n",
        "fs_prompt_chain = prompt_template | fs_model | StrOutputParser()\n",
        "\n",
        "# Following example llm code handout -- One-Shot: TD + one example\n",
        "fs_task_instruction = \"\"\"\n",
        "You are a review classifier. Your task is to classify a product review as either 'high-star' or 'low-star'.\n",
        "Output only 'high-star' or 'low-star'.\n",
        "\"\"\"\n",
        "\n",
        "# The in-context samples for one-shot and few-shot experiments must be taken from the training set\n",
        "fs_demonstrations = \"\"\"\n",
        "Example 1:\n",
        "Review: 'not bad but u can get better with same price. Three Stars'\n",
        "Output: low-star\n",
        "\n",
        "Example 2:\n",
        "Review: 'case white washes pics and is just too slippery.  felt as though it was cheaply made good\tDO NOT Buy!!!'\n",
        "Output: low-star\n",
        "\n",
        "Example 3:\n",
        "Review: 'it's an excellent case. nice color and protects the phone. i got this for my wife and she just loves it. Very good case'\n",
        "Output: high-star\n",
        "\"\"\"\n",
        "\n",
        "# Create an array to store predicted_labels based off of model\n",
        "fs_predicted_labels = []\n",
        "\n",
        "print(\"Few Shot data:\\n\")\n",
        "# Now loop through each row of data and apply the LLM:\n",
        "for review in llm_test_data['combinedData'][:15]:\n",
        "  print(\"Review: \", review)\n",
        "\n",
        "  few_shot_input = {\n",
        "        'instruction': fs_task_instruction,\n",
        "        'context': f\"{fs_demonstrations}\\n\\nReview to classify: {review}\"\n",
        "    }\n",
        "\n",
        "  try:\n",
        "    # Get model output\n",
        "    few_shot_output = fs_prompt_chain.invoke(few_shot_input)\n",
        "    print(\"Unextracted: \", few_shot_output)\n",
        "\n",
        "    # Extract the label from the model output for clarity\n",
        "    few_extracted_label = extract_label(few_shot_output)\n",
        "    print(\"Extracted: \", few_extracted_label)\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    # Append extracted label to the list\n",
        "    fs_predicted_labels.append(few_extracted_label)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"Error: \", e)"
      ],
      "metadata": {
        "id": "VvhliBahVTXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b7eb29-b81d-4509-db06-baf83f9e996f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few Shot data:\n",
            "\n",
            "Review:  cheap didn t last   year an i only used it for gaming one star\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  work great in my m  gbb  v tac bbs valken tactical     g bottle\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  love this case       durable and low profile five stars\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  all we have acquired smartphone blu brand  we know that we are excellent devices  particularly recommend  we know that we are excellent devices  particularly recommend\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  not attached yet   looks good   looks like it will work well  looks good   looks like it will work well\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  the case itself is nice  but the colors on the screen do not match the colors of the actual product   the aluminum portion is not what i would call red especially compared to the other parts of the case   it is a totally different color  it looks more like a rose color or mauve color to me and in different light can even take on a sort of rust color   i will keep the case  but will continue to look for something that is the color i wanted  aluminum plate is not red\n",
            "Unextracted:   Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  now i understand that the lighter roasts  such as lavazza  have the most caffeine   i went back to a darker bean  had me jumping\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  several issues with these mirrors  first the screw that holds the mirror to the stem month hold so the mirror just spins in circles  blue or red locktite will not hold  so i used jb welding to secure the post in place  second  the post for the adapters strip out and the whole mirror vibrates and starts spinning  blue and red locktite will not hold this in place so again i used jb welding to secure the post in the mirror  finally  after riding around and pressing the mirror back into place a small fracture developed allowing corrosion into the stem  while riding the stem snapped in half  so i am using jb welding to see if i can put it back together  buy these    and some jb weld\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  it looks good  but it has been falling apart since i first put it up  most of where the horizontal pieces meet the vertical pieces have come unglued with the slightest breeze  so i ve been stitching back together every day  at least i have a pattern to work from and didn t have to design it myself  fun design doesn t hold up to the wind\n",
            "Unextracted:   Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  actually i ordered this product by mistake   i wanted simply straight bands not knowing that loop bands are a different item entirely  i doubt if i ll use them but the price was reasonable and the quality is excellent  so i decided to keep them  maybe my kids can use them   i m too old for these  they are so dense i can hardly get them to stretch  top quality\n",
            "Unextracted:  \n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  looks great  poor lifespan buy extras   the lifespan is very poor\n",
            "Unextracted:   Output: low-star\n",
            "Extracted:  0\n",
            "\n",
            "\n",
            "\n",
            "Review:  too small for the phone   it is as if the phone is one eight inch too wide for it   sides did not fully wrap to the front   we went to the verizon store and bought theirs and they are working great  does not fit the icon\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  once again a great product from rcbs four stars\n",
            "Unextracted:   Output: high-star\n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  i ve read about half of the reviews of this cd that are posted here and i have listened to the cd at least    times  i don t understand those who dismiss down the road because it is not moondance or astral weeks  of course it isn t  but can t those critics hear that the spirit of those long ago days still haunts van morrison s soul \n",
            "personally  i think that this is van s best  most well rounded album since too long in exile  it has all the joyful bounce of street choir and moondance as well as a taste of his introspective mid period moods \n",
            "my favorites are talk is cheap  choppin  wood  ok  the background vocals are obnoxious but its still a great song   the maligned all work and no play  its those background vocals again   the soulful whatever happened to pj proby  only a dream  and evening shadows \n",
            "that last merits special mention  originally written as an instrumental by   s soft jazz pioneer acker bilk  van adds lyrics to evening shadows which really fit the music then brings bilk aboard to do a clarinet solo on his own music brought to life  tremendous \n",
            "about the only song i don t care for is van s rendition of georgia on my mind  but then that song has never been a favorite anyhow \n",
            "i m with the reviewer who said he did not care if van broke no new ground  he has given the world forty years of wonderful music and its hard to see what new ground he could possibly break  i highly recommend down the road to one and all  all the joy and beauty of days gone by\n",
            "Unextracted:   Output: high-star\n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n",
            "Review:  iconic  megadeth s crowning achievement  i first purchased this cd at the      release after seeing video on mtv  then saw them live at cow palace sf  during the countdown tour and have purchased many megadeth cd s since then  anyway this mobile fidelity      stereo only  right left sub  release remastered with dave mustaine himself is worth every penny of         the jewel case with pop up for cd is first i have seen  love it  the liner notes by mustaine are great  i am usually not a big fan of bonus tracks or demo s etc  but these   bonus tracks are as good as any on the entire cd and i am glad mustaine added them \n",
            "thanks mobile fidelity and megadeth  countdown to extinction explicit lyrics  limited edition  extra tracks\n",
            "Unextracted:  \n",
            "Extracted:  1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now report the results utilizing the data's confusion matrix:\n",
        "fs_tn, fs_fp, fs_fn, fs_tp = confusion_matrix(llm_labels[:15], fs_predicted_labels).ravel()\n",
        "\n",
        "# Calculating precision, recall, and f1 using equations from Lecture 9 slides: *making sure to avoid undefined results\n",
        "fs_accuracy = (fs_tp+fs_tn)/(fs_tp+fs_fn+fs_tn+fs_fp)\n",
        "fs_precision = fs_tp / (fs_tp+fs_fp) if (fs_tp + fs_fp) > 0 else 0\n",
        "fs_recall = fs_tp / (fs_tp+fs_fn) if (fs_tp + fs_fn) > 0 else 0\n",
        "fs_f1_macro = f1_score(llm_labels[:15], fs_predicted_labels, average='macro')\n",
        "\n",
        "\n",
        "# Print results:\n",
        "print(\"\\033[94m\", \"Results for Few Shot Model:\\n\")\n",
        "print(\"Accuracy: \", fs_accuracy)\n",
        "print(\"Precision: \", fs_precision)\n",
        "print(\"Recall: \", fs_recall)\n",
        "print(\"\\nF1 Macro: \", fs_f1_macro)"
      ],
      "metadata": {
        "id": "7a0TdAJxa3tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ed744f-6c1c-41e0-f4e7-ef17404bfff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m Results for Few Shot Model:\n",
            "\n",
            "Accuracy:  0.5333333333333333\n",
            "Precision:  0.5714285714285714\n",
            "Recall:  0.5\n",
            "\n",
            "F1 Macro:  0.5333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puCAvF3MowAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
